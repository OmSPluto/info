#1_web_scrap
pip install requests
pip install beautifulsoup4
import requests
from bs4 import BeautifulSoup
req = requests.get("https://www.geeksforgeeks.org/courses?source=google&medium=cpc&device=c&keyword=gfg%20courses&matchtype=e&campaignid=20039445781&adgroup=147845288105&gad_source=1&gclid=EAIaIQobChMIqKOB2r2GgwMVAqmDBx3zEgOdEAAYASAAEgJJYfD_BwE")
soup = BeautifulSoup(req.content, "html.parser")
print(soup.prettify)
print(soup.get_text())

#2_page_rank_analysis
import networkx as nx
import matplotlib.pyplot as plt
D = nx.DiGraph()
D.add_weighted_edges_from([('A', 'B', 1), ('A', 'C', 1), ('C', 'A', 1), ('B', 'C', 1)])
print(nx.pagerank(D))
pos = nx.spring_layout(D)
nx.draw(D, pos=pos, with_labels=True)
plt.show()

#3_sentiment_analysis_without_torch
import warnings
import pandas as pd
warnings.filterwarnings('ignore')
file_path = r'C:\Users\NILESH GOLATKAR\WebMining\hotel_reviews.csv'
df = pd.read_csv(file_path)
df.head()
import pandas as pd
#local directory
Reviewdata = pd.read_csv(r'C:\Users\NILESH GOLATKAR\WebMining\train - train.csv')
#Data Credit - https://www.kaggle.com/datasets/anu0012/hotel-review/data
Reviewdata.shape
Reviewdata.head()
Reviewdata.info()
Reviewdata.describe().transpose()
count = Reviewdata.isnull().sum().sort_values(ascending=False)
percentage = ((Reviewdata.isnull().sum()/len(Reviewdata)*100)).sort_values(ascending=False)
missing_data = pd.concat([count, percentage], axis=1, keys=['count','percentage'])
missing_data
import matplotlib.pyplot as plt
%matplotlib inline
print('Percentage for default\n')
print(round(Reviewdata.Is_Response.value_counts(normalize=True)*100,2))
round(Reviewdata.Is_Response.value_counts(normalize=True)*100,2).plot(kind='bar')
plt.title('Percentage Distribution by review type')
plt.show()
Reviewdata.drop(columns = ['User_ID', 'Browser_Used', 'Device_Used'], inplace = True)
import re       
import string
def text_clean_1(text):
    text = text.lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('\[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\w*\d\w', '', text)
    return text
cleaned = lambda x: text_clean_1(x)
Reviewdata['cleaned_description'] = pd.DataFrame(Reviewdata.Description.apply(cleaned))
Reviewdata.head(10)
#Apply a second round of cleaning
def text_clean_2(text):
    text = re.sub('[''""_]', '', text)
    text = re.sub('\n', '', text)
    return text
cleaned2 = lambda x: text_clean_2(x)
#Lets take a look at the updated text
Reviewdata['cleaned_description_new'] = pd.DataFrame(Reviewdata['cleaned_description'].apply(cleaned2))
Reviewdata.head(10)
from sklearn.model_selection import train_test_split
Independent_var = Reviewdata.cleaned_description_new
Dependent_var = Reviewdata.Is_Response
IV_train, IV_test, DV_train, DV_test = train_test_split(Independent_var, Dependent_var, test_size = 0.1, random_state = 225)
print('IV_train :', len(IV_train))
print('IV_test :', len(IV_test))
print('DV_train :', len(DV_train))
print('DV_test :', len(DV_test))
from sklearn.feature_extraction.text import  TfidfVectorizer          
from sklearn.linear_model import LogisticRegression
tvec = TfidfVectorizer()
clf2 = LogisticRegression(solver = "lbfgs")
from sklearn.pipeline import Pipeline
model = Pipeline([('vectorizer',tvec),('classifier',clf2)])
model.fit(IV_train, DV_train)
from sklearn.metrics import confusion_matrix
predictions = model.predict(IV_test)
confusion_matrix(predictions, DV_test)
from sklearn.metrics import accuracy_score, precision_score, recall_score
print("Accuracy : ", accuracy_score(predictions, DV_test))
print("Precision : ", precision_score(predictions, DV_test, average='weighted'))
print("Recall : ", recall_score(predictions, DV_test, average='weighted'))
example = [" I am delidgted"]
result = model.predict(example)
print(result)
example = [" I am disgusting"]
result = model.predict(example)
print(result)
example = [" I am "]
result = model.predict(example)
print(result)

#3_sentiment_analysis_with_torch
import pandas as pd
import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
Data_Path = "D:\\D Backup\\Datasets\\tripadvisor_hotel_reviews.csv"
df = pd.read_csv(Data_Path)
df.head()
neutral_range = {"low":4,"high":5}
df["Sentiment"] = "neutral"
